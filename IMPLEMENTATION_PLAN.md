# Implementation Plan

All phases complete. All 110 tests pass (101 oauth-proxy + 9 common, including 2 ignored soak/load tests). Binary sizes well under 15MB target. Both specs marked Complete.

Audits 1-48: Found and fixed 70+ issues across 48 audits including 5 bugs, spec documentation gaps, K8s security context issues, state machine correctness, metrics configuration, RUNBOOK accuracy, dependency upgrades, CI/CD blockers, live cluster deployment fixes, and test coverage gaps. Key milestones: 34th audit (v0.0.48) first clean audit; 44th audit (v0.0.63) deployment went live; 46th-49th audits found only test coverage gaps and dependency updates as the codebase stabilized.

Audits 50-55: Deep cross-cutting audits found and fixed PromQL aggregation, K8s probe gaps, CI vulnerability scanning, RUNBOOK documentation, and test coverage. Two consecutive clean audits (54th, 55th) with no code changes needed. See git history for details.

56th audit (v0.0.78): Updated spec status from Draft to Complete. Marked all success criteria and implementation phases as complete to match production reality (Aperture E2E traffic verified 2026-02-06). Documented `rustls-pemfile` unmaintained advisory.

57th audit (v0.0.79): Clean audit. Fixed tailnet.md spec status (Draft → Complete). Added test for non-default listen_addr preservation through state transitions. Added missing Proxy-Authenticate case-insensitive hop-by-hop test. No bugs found. 109 tests pass.

58th audit (v0.0.80): Clean audit. Three parallel code reviewers (main.rs, proxy/service/config/error, K8s/CI/Docker) found no bugs. Replaced `cargo install cargo-audit` in CI with `rustsec/audit-check@v2.0.0` action to eliminate 2-4 minutes of source compilation per CI run. All dependencies current except `matchit` 0.8.4 (blocked by axum pin). 109 tests pass.

59th audit (v0.0.81): Added tailscaled sidecar readiness probe and upgraded liveness probe. Containerboot's built-in `/healthz` HTTP endpoint (enabled via `TS_HEALTHCHECK_ADDR_PORT=127.0.0.1:9002`) replaces the socket existence check for liveness, and adds readiness gating so the pod isn't marked Ready until tailscaled has authenticated and received tailnet IPs. Updated RUNBOOK to document the new probe behavior. Full spec-vs-implementation audit found no bugs. All dependencies at latest compatible versions. 109 tests pass.

60th audit (v0.0.82): Added startupProbe to the tailscaled sidecar container. The 59th audit added liveness and readiness probes using the `/healthz` endpoint but kept the legacy `initialDelaySeconds: 10` pattern on liveness instead of a proper startupProbe. The liveness probe could kill tailscaled during slow tailnet authentication (e.g. coordination server latency). The new startupProbe gives tailscaled a 60-second startup budget (`periodSeconds: 2` x `failureThreshold: 30`), matching the proxy container's pattern. Removed `initialDelaySeconds` from liveness since the startup probe handles the startup window. Updated RUNBOOK to document the new three-probe configuration. Full codebase audit (main.rs, proxy/service/config/error, K8s/CI/Docker, common crate) found no bugs. All dependencies at latest compatible versions. 109 tests pass.

61st audit (v0.0.83): Infrastructure hardening. Full spec-vs-implementation audit confirmed 100% spec compliance — no code bugs found. Addressed CI and operational gaps: added `manifests` CI job that validates K8s manifests via `kubectl kustomize | kubectl apply --dry-run=client` to catch broken manifests before merge; added `if: github.event_name == 'push'` to Docker job to skip image builds on PRs (saves CI minutes since images are never pushed on PRs); added rollback procedure to RUNBOOK (`kubectl rollout undo`); clarified `ghcr-pull-secret` RUNBOOK wording to accurately describe Kubernetes warning behavior for missing `imagePullSecret` references; added explicit `type: ClusterIP` to service.yaml to document the deliberate choice. All 109 tests pass.

62nd audit (v0.0.84): Code quality and CI validation. Six parallel code reviewers audited proxy.rs, main.rs, service.rs, config/error/tailnet/metrics, K8s/CI/Docker, and dependencies. No bugs found. Removed unreachable defensive code after retry loop in proxy.rs — every code path through the loop returns or continues, so the post-loop fallback was dead code; replaced with `unreachable!()` per engineering philosophy of not handling scenarios that can't happen. Expanded state machine test coverage: renamed `connecting_ignores_listener_ready` to `connecting_ignores_unexpected_events` covering ConfigLoaded, RetryTimer, DrainTimeout, and RequestReceived; added `running_ignores_lifecycle_events` verifying Running state ignores ConfigLoaded, TailnetConnected, TailnetError, ListenerReady, RetryTimer, and DrainTimeout. Fixed Docker CI to build on PRs without pushing — the 61st audit's `if: github.event_name == 'push'` at the job level skipped Dockerfile validation entirely on PRs, meaning broken Dockerfiles could merge undetected. Moved the condition to the login step only; the build step always runs but push remains gated on main/tags. All dependencies current. 110 tests pass (101 oauth-proxy + 9 common).

63rd audit (v0.0.85): Clean audit. Four parallel reviewers (Rust source, K8s/CI/Docker, test runner, dependency checker) plus upstream dependency research. No bugs found. No code changes needed. All 110 tests pass (101 oauth-proxy + 9 common). All dependencies at latest compatible versions. Checked upstream: `tailscale-localapi` still at v0.4.2 (no release to resolve `rustls-pemfile` RUSTSEC-2025-0134); axum still at v0.8.8 with `matchit = "=0.8.4"` exact pin (PRs #3143 and #3568 remain open/draft). Third consecutive clean audit (62nd had code changes, 63rd is the first fully clean since 55th).

## Remaining Work

All implementation items complete. Aperture integration verified with live E2E traffic on 2026-02-06. Spec updated to Complete status.

- [ ] Long-term production monitoring — observe traffic patterns, error rates, and resource usage over time

## Known Limitations

- Health endpoint `tailnet` state is set once at startup and never updated during operation. If tailscaled drops during runtime, health still reports `"connected"`. Fixing this requires tailnet health monitoring (periodic polling of tailscaled), which is infrastructure work beyond the current spec. The `tailnet_connected` Prometheus gauge does get set to `false` during graceful shutdown.
- `ConfigError` and `ListenerBindError` are not in the service's Rust error enum. Config errors use `common::Error` and listener bind errors use `anyhow`. These paths work correctly; the spec now documents this split explicitly.
- `rustls-pemfile` v1.0.4 is unmaintained (RUSTSEC-2025-0134). This is a transitive dependency via `tailscale-localapi` v0.4.2. The maintained successor functionality lives in `rustls-pki-types`. Resolving requires `tailscale-localapi` to update upstream. No security vulnerability, only maintenance status.
- `matchit` 0.8.4 → 0.8.6 update blocked by axum v0.8.8's exact version pin (`matchit = "=0.8.4"`). Requires axum release with updated pin.

## Learnings

- Reverse proxies must strip the client's `host` header before forwarding. The client sends `Host: <proxy-address>` but the upstream expects `Host: <upstream-address>`. HTTP client libraries like reqwest automatically set the correct Host from the URL, but only if the incoming Host isn't manually set in the header map.
- Config-driven header injection must protect safety-critical headers. The `authorization` header should never be overwritable via config, even if someone misconfigures it. This is a system boundary validation.
- When copying HTTP headers in a proxy, use `append()` not `insert()` to preserve multi-value headers. `insert()` replaces, `append()` accumulates. This matters for headers like Cookie, Accept-Encoding, and custom multi-value headers.
- Rust 2024 edition requires `unsafe {}` blocks inside `unsafe fn` bodies. Tests that call `std::env::set_var`/`remove_var` (unsafe since Rust 1.83) need both the `unsafe fn` wrapper and inner `unsafe {}` blocks.
- Tests that mutate environment variables must be serialized with a `Mutex` to prevent data races when `cargo test` runs in parallel (default behavior). Without this, env-var-dependent tests fail nondeterministically.
- `tracing-subscriber` requires the `env-filter` feature for `EnvFilter` support. The `json` feature alone is not sufficient.
- Drain coordination: axum's `with_graceful_shutdown` handles connection-level draining (stops accepting new connections, waits for in-flight to finish), but it waits indefinitely by default. The spec requires a 5-second drain timeout. Enforced by spawning the server as a task, signaling it via a `oneshot` channel on SIGTERM/SIGINT, then racing the drain against `DRAIN_TIMEOUT` using `tokio::time::timeout`.
- `tailscale-localapi` v0.4.2 uses `chrono` for timestamps and brings in `hyper` v0.14 (in addition to the workspace's `hyper` v1). This is expected — the crate was built against an older `hyper` API.
- On macOS with the App Store Tailscale variant, there is no Unix socket. The fallback is `tailscale status --json` which parses the same `Status` type via `serde_json`.
- `metrics-exporter-prometheus` global recorder can only be installed once per process. In tests, use `PrometheusBuilder::build_recorder()` + `.handle()` to create isolated instances without global installation.
- Integration tests using `tower::ServiceExt::oneshot` give full end-to-end coverage without needing to bind a TCP port — they call the axum router directly as a tower Service.
- Cross-compilation from macOS to Linux requires `cargo-zigbuild` (uses zig as the C cross-linker). Standard `cargo build --target` fails because `aws-lc-sys` needs a C cross-compiler.
- `reqwest` with default features enabled pulls in `native-tls` → `openssl-sys` on Linux targets, even when `rustls-tls` is also enabled. Setting `default-features = false` is required to avoid the OpenSSL dependency.
- `tower` crate requires explicit feature flags for each layer type. `ConcurrencyLimitLayer` requires the `limit` feature.
- `BackendState` enum in `tailscale-localapi` is `#[non_exhaustive]`, requiring wildcard match arms.
- Tower's `ConcurrencyLimitLayer` queues excess requests rather than rejecting them. Requests above `max_connections` will wait (not fail) until a slot opens.
- Docker build uses native `x86_64-unknown-linux-gnu` target (not musl) inside `rust:1-bookworm`. No cross-compilation needed since Docker IS Linux.
- K8s manifests use `TS_USERSPACE=true` for the tailscaled sidecar to avoid requiring `NET_ADMIN` capabilities. The proxy and tailscaled share the Unix socket via an `emptyDir` volume.
- GitHub Actions CI uses `actions/checkout@v6`, `dtolnay/rust-toolchain@stable`, `Swatinem/rust-cache@v2`, and `rustsec/audit-check@v2.0.0`. All jobs have explicit least-privilege `permissions` blocks. Docker job uses `docker/build-push-action@v6` with GHA cache. Images push to GHCR using the built-in `GITHUB_TOKEN`.
- `BackendState::NeedsMachineAuth` requires manual admin approval in the Tailscale console. Mapping it to a retryable error wastes 31 seconds of exponential backoff before giving up. It must be non-retryable.
- A spec-vs-implementation audit is valuable after completing major phases. Found 43+ discrepancies across ten audits including 5 bugs, spec documentation gaps, and positive deviations. The tenth audit found 1 state machine bug (terminal state not fully inert).
- Terminal states in a state machine must be explicitly guarded before wildcard match arms. Without a `Stopped` guard before `(_, ShutdownSignal)`, the wildcard produces a `Shutdown` action from an already-stopped state, violating the "terminal means inert" invariant.
- K8s sidecar pattern requires both containers to mount the shared volume. The volume definition in `spec.volumes` is not enough — each container that needs the socket must have a `volumeMount` entry. Easy to miss because the tailscaled container (which creates the socket) works fine; only the consumer (proxy) fails.
- Response bodies must be streamed, not buffered, in a proxy targeting the Claude API. The Anthropic API uses SSE (Server-Sent Events) for streaming responses. Buffering breaks real-time delivery and uses unbounded memory. Use `reqwest::Response::bytes_stream()` with `axum::body::Body::from_stream()`. Metrics (status, duration) must be collected before consuming the stream since headers are available immediately.
- Config validation at system boundaries catches misconfigurations early: `upstream_url` must have an http(s) scheme, `timeout_secs` and `max_connections` must be non-zero. Without URL scheme validation, reqwest fails at request time with a confusing error instead of at startup.
- `metrics-exporter-prometheus` renders `metrics::histogram!()` as a Prometheus summary (quantiles) by default. To get a true histogram (with `_bucket` lines needed by `histogram_quantile()` queries), you must configure explicit bucket boundaries via `set_buckets_for_metric()`. Without this, RUNBOOK PromQL queries referencing `_bucket` will fail silently.
- In a sidecar pattern, secrets should only be mounted in the container that consumes them. `TS_AUTHKEY` belongs on the tailscaled sidecar, not the proxy container — the proxy queries tailnet state via the Unix socket and never authenticates directly.
- Spec dependency lists can drift from the actual Cargo.toml when features are added during implementation. The `"stream"` feature on reqwest was added for response streaming but the spec's Build & Distribution section was not updated. Always update the spec when adding dependency features.
- Dockerfiles for K8s pods with `runAsNonRoot: true` must create the non-root user in the image. `debian:bookworm-slim` only has root; use `useradd -u 1000 -r -s /sbin/nologin appuser` and `USER 1000` in the runtime stage. Without this, the pod crashes with `CreateContainerConfigError`. Avoid the username `proxy` — it's a Debian standard system user (UID 13).
- `reqwest::Client::new()` uses unbounded connection pool defaults. For a proxy with configurable `max_connections`, set `connect_timeout()` and `pool_max_idle_per_host()` on the builder to prevent unbounded TCP connections when upstream is slow to accept.
- K8s Pod Security Standards (restricted profile) require `allowPrivilegeEscalation: false`, `readOnlyRootFilesystem: true`, and `capabilities: { drop: ["ALL"] }` on every container. Missing these can block deployment to hardened clusters.
- Using `:latest` for sidecar images in K8s deployments breaks reproducibility and rollbacks. Pin to specific versions (e.g. `tailscale:v1.94.1`) so that `kubectl rollout undo` works predictably.
- State machine variants should only carry data they own and use. The `Running` state had a `ServiceMetrics` that was never read because `main.rs` creates its own metrics instance wired to `ProxyState`. Dead allocations in state variants waste memory and confuse readers.
- K8s `terminationGracePeriodSeconds` should be DRAIN_TIMEOUT + small buffer (e.g. 1s), not significantly larger. The application force-exits after DRAIN_TIMEOUT regardless, so the extra Kubernetes wait is wasted delay during rolling updates and node drains.
- Kustomize secrets with placeholder values overwrite real secrets on `kubectl apply -k`. If a secret contains a real credential created imperatively, do NOT include it in `kustomization.yaml`. Keep a schema-documenting `secret.yaml` in the repo but excluded from kustomization resources. The RUNBOOK should instruct users to create the secret imperatively after `kubectl apply -k`.
- K8s Pod Security Standards restricted profile requires `runAsNonRoot: true` on every container, not just the main application container. Setting `runAsUser: 1000` is not sufficient — the explicit `runAsNonRoot` field is what Kubernetes admission controllers check. Missing it on sidecar containers is easy to overlook.
- Prometheus histograms and summaries are different metric types with different semantics. Histograms produce `_bucket`, `_sum`, and `_count` lines; quantiles are computed at query time via `histogram_quantile()`. Summaries compute quantiles client-side. Documentation must use precise terminology — saying a histogram "automatically computes quantiles" is misleading and confuses operators writing PromQL.
- Undocumented environment variable overrides create debugging blind spots. If code reads an env var to override defaults (like `TAILSCALE_SOCKET` for the socket path), it must be documented in both the spec's environment variables table and the operational runbook's troubleshooting section.
- Crate `derive` features (e.g. `zeroize = { features = ["derive"] }`) pull in proc-macro dependencies (`syn`, `quote`, `proc-macro2`). Only enable them if `#[derive(Trait)]` is actually used. Using a trait as a bound or calling methods directly does not require the derive feature.
- Concurrency limits on a proxy must exclude observability endpoints. K8s liveness/readiness probes and Prometheus scrapes must always be responsive regardless of proxy load. In axum, use `Router::merge()` to nest a concurrency-limited sub-router (proxy routes) under an unlimited parent router (health/metrics routes).
- K8s secret rotation should use `kubectl create --dry-run=client -o yaml | kubectl apply -f -` for atomic updates. A `delete` then `create` sequence leaves a window where pods rescheduled between the two commands fail with `CreateContainerConfigError`.
- Minimal Docker images (debian-slim + ca-certificates only) don't have debugging tools like `curl`. RUNBOOK troubleshooting steps should use `kubectl port-forward` from the operator's workstation instead of `kubectl exec` with tools that aren't in the image.
- K8s restricted pod security profile requires pod-level `securityContext` with `seccompProfile.type: RuntimeDefault`. Container-level security contexts alone are insufficient — admission controllers check the pod-level seccomp profile separately. Also set `fsGroup` at the pod level so emptyDir volumes are writable by the non-root group.
- `unreachable!()` in non-test code paths is a latent process abort, especially with `panic = "abort"` in the release profile. Even if the current caller never triggers the arm, future code changes might. Replace `unreachable!()` with defensive no-op returns in state machines where the arm is theoretically reachable but practically unused.
- K8s resources should carry consistent `app:` labels even if they are not selected by anything. Labels enable `kubectl get <kind> -l app=<name>` queries for discovering all resources belonging to a project, which aids operational debugging and bulk cleanup.
- reqwest 0.13 renamed the `rustls-tls` feature to `rustls`. The `.query()` and `.form()` RequestBuilder methods are now behind opt-in feature flags (`query`, `form`). TLS-related ClientBuilder methods got `tls_` prefixes (old names still work but are deprecated). If using `default-features = false`, the only required change is the feature rename.
- K8s pods with sidecar dependencies need startup probes, not just liveness/readiness probes. Without a startup probe, the liveness probe's `initialDelaySeconds` is a fixed guess at how long startup takes. A startup probe with `failureThreshold * periodSeconds` provides a proper startup budget (e.g. 30 * 2s = 60s) and once it succeeds, liveness/readiness probes take over. This prevents premature restarts when the sidecar (tailscaled) takes longer than expected to authenticate.

- RUNBOOK example responses must reflect actual runtime behavior, not idealized static values. The degraded health endpoint returns real `uptime_seconds`, `requests_served`, and `errors_total` values (not zeros), because these counters run regardless of tailnet connection state. Hardcoding zeros in documentation misleads operators into thinking these fields are meaningless when degraded.
- `docker/build-push-action@v6` with `cache-from/cache-to: type=gha` requires `docker/setup-buildx-action@v3` in the workflow. The default docker driver does not support GHA cache export. Without the buildx setup step, the build fails with "Cache export is not supported for the docker driver."
- `debian:bookworm-slim` includes a system user named `proxy` (UID 13). Creating a custom user with `useradd ... proxy` fails. Use a different username like `appuser` for application-specific non-root users to avoid conflicts with Debian standard system users.
- Tailscale container image v1.94.1 has K8s-aware startup that tries to manage its own state via K8s secrets. If running as a sidecar without RBAC for secret access, set `TS_KUBE_SECRET=""` to disable K8s secret storage and fall back to filesystem state in the `TS_STATE_DIR` emptyDir volume. Without this, the sidecar fails with "missing get permission on secret tailscale".
- Private GitHub repos produce private GHCR packages. The `GITHUB_TOKEN` in GitHub Actions has `packages:write` for push/pull registry operations but fundamentally cannot change package visibility via the REST API — this is a long-standing GitHub limitation (since 2021, still unresolved). A CI step using `gh api --method PATCH /user/packages/... -f visibility=public` with `GITHUB_TOKEN` silently fails even with `|| true`. The only ways to change visibility are: (1) the GitHub web UI, (2) a classic PAT with `write:packages` scope, or (3) changing account-level default package visibility to "Public" in Settings → Packages. The `gh` CLI `gho_` OAuth token has `repo` scope but not `read:packages`, so even `gh api` calls to query packages fail with 403.
- Tailscale auth keys for sidecar pods should be **reusable** and **ephemeral**. Single-use keys get consumed on the first pod creation and fail on restarts. Ephemeral keys auto-deregister the node when it goes offline, preventing stale device accumulation. Create via Tailscale API using the operator's OAuth credentials: exchange OAuth client credentials for an access token, then POST to `/api/v2/tailnet/-/keys`.
- Kubernetes `capabilities.add` is inert for non-root containers on containerd. Containerd clears the ambient capability set for non-root users, so added capabilities sit in bounding/inheritable sets but never reach the effective set where syscalls check them. `allowPrivilegeEscalation: false` compounds this via `no_new_privs`, but even without it, ambient caps are cleared. This is containerd issue #5644 (closed "not planned") and KEP-2763 (unimplemented). The 37th audit's `CAP_FOWNER` fix was a no-op.
- Tailscale v1.94.1 `ensureStateDirPermsUnix` calls `chmod` on the state directory when permissions don't match `0700`. With `fsGroup: 1000`, Kubernetes sets directory permissions to `2755` (setgid), triggering the chmod. The function has a guard: it only runs when `filepath.Base(dir) == "tailscale"`. Fix: rename the state directory from `/var/lib/tailscale` to `/var/lib/ts-state` so the basename bypasses the guard entirely. This avoids needing capabilities, init containers, or running as root.
- K8s deployment requires both GHCR package access AND Tailscale auth key secret. The ghcr-pull-secret exists but its token lacks `read:packages` scope. Both must be functional before pods can start.
- K8s deployments using mutable image tags (`:main`, `:latest`) must set `imagePullPolicy: Always` explicitly. The Kubernetes default `IfNotPresent` caches images by tag, so updated images pushed to the same tag are never pulled. Pinned tags (`:v1.94.1`) can use `IfNotPresent` since the content is immutable.
- CI workflows with `docker/metadata-action` semver tag patterns (`type=semver,pattern={{version}}`) require the workflow `on.push.tags` trigger to include `v*` or equivalent. Without it, tag pushes never fire the workflow and the semver metadata patterns are dead code. The push condition also needs updating to allow tag refs, not just `refs/heads/main`.
- Prometheus pod annotations (`prometheus.io/scrape`, `prometheus.io/port`, `prometheus.io/path`) must be on the pod template metadata, not the Deployment metadata. Prometheus discovers scrape targets at the pod level. Without these, the RUNBOOK's "scrape `/metrics` on port 8080" instruction has no mechanism for auto-discovery.
- Docker builds without a `.dockerignore` send the entire repository as build context to the daemon, including `.git/`, `.specstory/`, `k8s/`, `specs/`, and documentation. None of these are needed in the image. A `.dockerignore` reduces context transfer time and prevents accidental inclusion of sensitive files.
- K8s `imagePullSecrets` that reference nonexistent secrets are tolerated when anonymous pulls succeed (public registry). But if the image is private, the missing secret causes `ErrImagePull` with no hint about the secret — operators need clear documentation of all prerequisite secrets.
- K8s liveness probes without `failureThreshold` default to 3 failures, but explicitly setting it documents intent and prevents confusion. For services with sidecar dependencies (tailscaled), the liveness probe must tolerate transient disconnects — if the tailnet coordinator is briefly unreachable, restarting the pod only makes things worse. Set `failureThreshold` to match the expected reconnection window (e.g. 3 failures × 15s period = 45s tolerance).
- Environment variables that create implicit contracts between containers in a pod should be explicit on both sides. If the tailscaled sidecar sets `TS_SOCKET=/var/run/tailscale/tailscaled.sock` and the proxy defaults to the same path, the contract is fragile — changing one side silently breaks the other. Setting `TAILSCALE_SOCKET` explicitly on the proxy container documents the dependency and makes mismatches immediately visible in `kubectl describe`.
- `cargo audit` scans Cargo.lock against the RustSec Advisory Database for known vulnerability advisories. Unlike `cargo clippy` (which finds code patterns), `cargo audit` catches supply-chain issues in dependencies that the project has no control over. Adding it as a CI gate catches advisories before they reach production images.
- PromQL `histogram_quantile()` requires a single time series per `le` bucket. When a histogram has additional labels (e.g. `status`), the query must use `sum by (le)` to aggregate across label values before passing to `histogram_quantile()`. Without this, the function receives multiple series per bucket and produces incorrect results or "not a valid histogram" errors. Easy to miss in runbooks because the query works fine with a single status code but breaks as soon as a second status appears.
- Tailscale containerboot (v1.72+) exposes a built-in `/healthz` HTTP endpoint via `TS_HEALTHCHECK_ADDR_PORT`. It returns 200 with "ok" when the node has at least one tailnet IP, and 503 when not connected. This is superior to the socket existence check (`test -S <socket-path>`) because: (1) it verifies tailscaled is authenticated, not just that the process started; (2) it enables proper readiness gating — the pod isn't marked Ready until the tailnet connection is established; (3) it uses the standard HTTP probe type instead of exec, reducing kubelet overhead. Bind to loopback (`127.0.0.1:9002`) to avoid exposing the endpoint on the tailnet.
- K8s probe fields that default to reasonable values (like `failureThreshold: 3`) should still be set explicitly when the value represents a deliberate operational decision. Implicit defaults work but don't communicate intent — future operators may not know whether the omission was deliberate or accidental.
- Transitive dependency updates may be blocked by exact version pins in upstream crates. axum v0.8.8 pins `matchit = "=0.8.4"` (exact), so `cargo update matchit --precise 0.8.6` fails. The only fix is waiting for axum to release with the updated pin. `cargo update --dry-run --verbose` reveals these blocked updates.
- Measuring process RSS in Rust requires platform-specific code: `mach_task_basic_info` via `task_info()` on macOS, `/proc/self/statm` on Linux. The `libc` crate deprecates its Mach wrappers (`mach_task_self()`, `mach_task_self_`) in favor of the `mach2` crate, but `mach2` v0.4 lacks the `mach_task_basic_info` struct definition — only constants are exported. Use `libc` with `#[allow(deprecated)]` until `mach2` catches up. A compressed soak test (20K requests after warmup, asserting <5 MiB RSS growth) can validate the "zero memory growth" spec criterion without a real 24-hour run — any per-request leak of 256+ bytes would exceed the threshold.

- `rustls-pemfile` v1.x is unmaintained (RUSTSEC-2025-0134). Its functionality was absorbed into `rustls-pki-types`. This crate enters the dependency tree via `tailscale-localapi` v0.4.2. No security vulnerability — purely a maintenance status advisory. The `cargo audit` CI job reports it as a warning, not a failure, because the `--deny warnings` flag is not set (advisories without CVSS scores are informational).
- `rustsec/audit-check@v2.0.0` is the official GitHub Action for cargo-audit. It handles installation, advisory database fetching, and GitHub check creation automatically. Using `cargo install cargo-audit` in CI compiles from source on every run (2-4 minutes), which is wasteful since the action provides a pre-built binary. The action requires `token: ${{ secrets.GITHUB_TOKEN }}` for creating GitHub checks.
- CI workflows should validate K8s manifests with `kubectl kustomize <dir> | kubectl apply --dry-run=client -f -`. This catches YAML syntax errors, invalid field names, and schema violations before merge. GitHub-hosted runners include `kubectl` by default, so no additional tooling setup is needed.
- Docker CI jobs should always run the build (even on PRs) to validate the Dockerfile compiles. Gate the registry login step with `if: github.event_name == 'push'` and gate the push flag on the build step. Gating the entire job with `if: github.event_name == 'push'` saves CI time but creates a validation gap — broken Dockerfiles merge undetected because the build never runs on PRs.
- K8s Service `type` defaults to `ClusterIP` when omitted. While the default is correct for tailnet-only services, omitting it creates ambiguity for operators reading the manifest — they cannot distinguish "deliberately ClusterIP" from "forgot to set it." Explicit defaults communicate intent.

## Environment Notes

- Rust toolchain: cargo 1.93.0, rustc 1.93.0 (stable, Jan 2026), installed at `~/.cargo/bin/cargo`
- Cross-compilation: `cargo-zigbuild` v0.21.6 + zig 0.15.2 for Linux targets
